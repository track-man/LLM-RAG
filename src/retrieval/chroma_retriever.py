"""
åŸºäºChromaDBçš„æ£€ç´¢æ¨¡å— - ä½¿ç”¨bge-base-en-v1.5åµŒå…¥æ¨¡å‹
"""
import os

os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Dict, Any, Optional, Union
import logging
from pathlib import Path



logger = logging.getLogger(__name__)

class ChromaRetriever:
    """ChromaDBæ£€ç´¢å™¨ - ä½¿ç”¨bge-base-en-v1.5åµŒå…¥æ¨¡å‹"""
    
    def __init__(self, 
                 db_path: str = "data/chroma_db",
                 collection_name: str = "documents",
                 embedding_model: str = "BAAI/bge-base-en-v1.5",
                 reset_collection: bool = False):  # æ–°å¢å‚æ•°  11/12ä¿®æ”¹å¢åŠ 
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨
        
        Args:
            db_path: ChromaDBæ•°æ®åº“è·¯å¾„
            collection_name: é›†åˆåç§°
            embedding_model: åµŒå…¥æ¨¡å‹åç§°
            reset_collection: æ˜¯å¦é‡ç½®é›†åˆ
        """
        self.db_path = Path(db_path)
        self.collection_name = collection_name
        self.model_name = embedding_model
        self.reset_collection = reset_collection  # æ–°å¢å‚æ•°  11/12ä¿®æ”¹å¢åŠ 
        
        # æ£€ç´¢å‚æ•°
        self.default_top_k = 5
        self.similarity_threshold = 0.7
        
        # ç»„ä»¶
        self.client = None
        self.collection = None
        self.embedder = None
        
        self._initialize_components()
    
    def _initialize_components(self):
        """åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯å’ŒåµŒå…¥æ¨¡å‹"""
        try:
            logger.info("åˆå§‹åŒ–ChromaDBæ£€ç´¢å™¨...")
            
            # åˆ›å»ºæ•°æ®åº“ç›®å½•
            self.db_path.mkdir(parents=True, exist_ok=True)
            
            # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
            self.client = chromadb.PersistentClient(path=str(self.db_path))
            logger.info(f"ChromaDBå®¢æˆ·ç«¯åˆå§‹åŒ–: {self.db_path}")
            

            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            logger.info(f"åŠ è½½åµŒå…¥æ¨¡å‹: {self.model_name}")
            self.embedder = SentenceTransformer(self.model_name)

            # éªŒè¯æ¨¡å‹ç»´åº¦
            test_embedding = self.embedder.encode(["test"])
            logger.info(f"åµŒå…¥ç»´åº¦: {len(test_embedding[0])}")
            logger.info("åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")

            # å¤„ç†é›†åˆåˆ›å»º/é‡ç½®é€»è¾‘
            if self.reset_collection:
                try:
                    self.client.delete_collection(self.collection_name)
                    logger.info(f"å·²åˆ é™¤ç°æœ‰é›†åˆ: {self.collection_name}")
                except Exception as e:
                    logger.info(f"åˆ é™¤é›†åˆæ—¶å¿½ç•¥é”™è¯¯ï¼ˆå¯èƒ½é›†åˆä¸å­˜åœ¨ï¼‰: {e}")

                # åˆ›å»ºæ–°é›†åˆ    
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    embedding_function=self._get_embedding_function(),
                    metadata={"description": "Document chunks for RAG system"}
                )
                logger.info(f"âœ… åˆ›å»ºæ–°é›†åˆæˆåŠŸ: {self.collection_name}")
            else:
                try:
                    self.collection = self.client.get_collection(name=self.collection_name)
                    logger.info(f"ä½¿ç”¨ç°æœ‰é›†åˆ: {self.collection_name}")
                except Exception:
                    # é›†åˆä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é›†åˆ
                    self.collection = self.client.create_collection(
                        name=self.collection_name,
                        embedding_function=self._get_embedding_function(),
                        metadata={"description": "Document chunks for RAG system"}
                )
                logger.info(f"åˆ›å»ºæ–°é›†åˆ: {self.collection_name}")

                 # éªŒè¯é›†åˆæ˜¯å¦æˆåŠŸè®¾ç½®
            if self.collection is None:
                logger.error("é›†åˆåˆå§‹åŒ–å¤±è´¥ï¼šcollectionä¸ºNone")
                raise RuntimeError("é›†åˆåˆå§‹åŒ–å¤±è´¥")
        
            logger.info("âœ… æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.collection = None
            raise
    
    def _get_embedding_function(self):
    # """è·å–è‡ªå®šä¹‰åµŒå…¥å‡½æ•°"""
    # å®šä¹‰ç¬¦åˆChromaDBæ–°æ¥å£è¦æ±‚çš„åµŒå…¥å‡½æ•°ç±»
        class CustomEmbeddingFunction:
            def __init__(self, embedder):
                self.embedder = embedder
            
            def __call__(self, input):
            # """ChromaDBè¦æ±‚çš„åµŒå…¥å‡½æ•°ç­¾å"""
                if isinstance(input, str):
                    texts = [input]
                else:
                    texts = input

                if not texts:
                    return []
            
            # ä½¿ç”¨bgeæ¨¡å‹ç”ŸæˆåµŒå…¥
                embeddings = self.embedder.encode(texts)
                return embeddings.tolist()
    
        return CustomEmbeddingFunction(self.embedder)
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥æ£€ç´¢å™¨æ˜¯å¦å°±ç»ª"""
        if not all([self.client, self.collection, self.embedder]):
            logger.warning(f"ç»„ä»¶æœªå°±ç»ª: client={self.client is not None}, "
                      f"collection={self.collection is not None}, "
                      f"embedder={self.embedder is not None}")
            return False
        return True
    
    def retrieve_similar_chunks(self, 
                               query: str,
                               top_k: Optional[int] = None,
                               similarity_threshold: Optional[float] = None) -> List[Dict[str, Any]]:
        """
        åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³æ–‡æ¡£å—
        """
        if not self.is_ready():
            logger.error("æ£€ç´¢å™¨æœªå°±ç»ª")
            return []
            
        top_k = top_k or self.default_top_k
        threshold = similarity_threshold or self.similarity_threshold
        
        try:
            logger.info(f"æ‰§è¡Œè¯­ä¹‰æ£€ç´¢: '{query}'")
            
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k,
                include=["metadatas", "documents", "distances"]
            )
            
            processed_results = []
            if results['documents'] and len(results['documents'][0]) > 0:
                documents = results['documents'][0]
                metadatas = results['metadatas'][0] if results['metadatas'] else [{}] * len(documents)
                distances = results['distances'][0] if results['distances'] else [0.0] * len(documents)
                ids = results['ids'][0] if results['ids'] else [f"result_{i}" for i in range(len(documents))]
                
                for i, (doc, metadata, distance, doc_id) in enumerate(zip(documents, metadatas, distances, ids)):
                    similarity = self._distance_to_similarity(distance)
                    
                    if similarity >= threshold:
                        result = {
                            'id': doc_id,
                            'content': doc,
                            'metadata': metadata,
                            'similarity_score': similarity,
                            'distance': distance,
                            'rank': i + 1
                        }
                        processed_results.append(result)
            
            logger.info(f"è¯­ä¹‰æ£€ç´¢å®Œæˆ: {len(processed_results)} ä¸ªç»“æœ")
            return processed_results
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def retrieve_by_metadata(self, 
                           filters: Dict[str, Any],
                           limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """åŸºäºå…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢æ–‡æ¡£"""
        if not self.is_ready():
            logger.error("æ£€ç´¢å™¨æœªå°±ç»ª")
            return []
            
        try:
            logger.info(f"æ‰§è¡Œå…ƒæ•°æ®æ£€ç´¢: {filters}")
            
            results = self.collection.query(
                query_texts=[""],  # ç©ºæŸ¥è¯¢ï¼Œåªä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤
                n_results=limit or self.default_top_k,
                where=filters,
                include=["metadatas", "documents"]
            )
            
            processed_results = []
            if results['documents'] and len(results['documents'][0]) > 0:
                documents = results['documents'][0]
                metadatas = results['metadatas'][0] if results['metadatas'] else [{}] * len(documents)
                ids = results['ids'][0] if results['ids'] else [f"meta_{i}" for i in range(len(documents))]
                
                for i, (doc, metadata, doc_id) in enumerate(zip(documents, metadatas, ids)):
                    processed_results.append({
                        'id': doc_id,
                        'content': doc,
                        'metadata': metadata,
                        'match_type': 'metadata_filter',
                        'rank': i + 1
                    })
            
            logger.info(f"å…ƒæ•°æ®æ£€ç´¢å®Œæˆ: {len(processed_results)} ä¸ªç»“æœ")
            return processed_results
            
        except Exception as e:
            logger.error(f"å…ƒæ•°æ®æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def add_documents(self, documents: List[str], metadatas: List[Dict] = None, ids: List[str] = None):
        """æ·»åŠ æ–‡æ¡£åˆ°é›†åˆ"""
        if not self.is_ready():
            logger.error("æ£€ç´¢å™¨æœªå°±ç»ª")
            return False
            
        try:
            if metadatas is None:
                metadatas = [{} for _ in documents]
            if ids is None:
                ids = [f"doc_{i}" for i in range(len(documents))]
                
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            logger.info(f"æˆåŠŸæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")
            return True
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        ä¸ºæ–‡æœ¬åˆ—è¡¨ç”ŸæˆåµŒå…¥å‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not self.is_ready():
            logger.error("æ£€ç´¢å™¨æœªå°±ç»ª")
            return []
            
        try:
            embeddings = self.embedder.encode(texts)
            return embeddings.tolist()
        except Exception as e:
            logger.error(f"ç”ŸæˆåµŒå…¥å¤±è´¥: {e}")
            return []
    
    def _distance_to_similarity(self, distance: float) -> float:
        """å°†ChromaDBè·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°"""
        similarity = 1.0 - (distance / 2.0)
        return max(0.0, min(1.0, similarity))
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        if not self.is_ready():
            return {"status": "not_ready"}
            
        try:
            count = self.collection.count()
            return {
                "collection_name": self.collection_name,
                "document_count": count,
                "embedding_model": self.model_name,
                "database_path": str(self.db_path)
            }
        except Exception as e:
            logger.error(f"è·å–é›†åˆç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ§ª æµ‹è¯•ä½¿ç”¨bge-base-en-v1.5çš„ChromaRetriever...")
    
    try:
        # åˆ›å»ºæ£€ç´¢å™¨å®ä¾‹å¹¶é‡ç½®é›†åˆ  11/12ä¿®æ”¹å¢åŠ é‡ç½®å‚æ•°
        retriever = ChromaRetriever(
            db_path="test_chroma_db",
        reset_collection=True  # é‡ç½®ç°æœ‰é›†åˆ
)
        # åˆ›å»ºæ£€ç´¢å™¨å®ä¾‹
        # 11/12ä¿®æ”¹åˆ é™¤  retriever = ChromaRetriever(db_path="test_chroma_db")
        
        # æ£€æŸ¥æ˜¯å¦å°±ç»ª
        print(f"æ£€ç´¢å™¨å°±ç»ªçŠ¶æ€: {retriever.is_ready()}")
        
        # è·å–é›†åˆä¿¡æ¯
        stats = retriever.get_collection_stats()
        print(f"é›†åˆä¿¡æ¯: {stats}")
        
        # æµ‹è¯•åµŒå…¥ç”Ÿæˆ
        test_texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£", "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"]
        embeddings = retriever.generate_embeddings(test_texts)
        print(f"åµŒå…¥å‘é‡ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
        
        print("âœ… ChromaRetriever æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
