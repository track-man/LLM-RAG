# LLM配置
deepseek:
  provider: "deepseek"
  api_key: "${DEEPSEEK_API_KEY}"  # 从环境变量读取
  base_url: "https://api.deepseek.com/v1"
  model: "deepseek-chat"
  max_tokens: 2000
  temperature: 0.1
  timeout: 30

openai:
  provider: "openai"
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-3.5-turbo"
  max_tokens: 1000
  temperature: 0.1